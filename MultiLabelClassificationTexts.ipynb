{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text multi-label classification using Keras\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite database data to csv conversion\n",
    "---\n",
    "Based on [this documentation](https://www.sqlitetutorial.net/sqlite-python/sqlite-python-select/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQLITE_FILE = 'database.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_entities(conn, db_name):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"SELECT * FROM {db_name}\")\n",
    "    \n",
    "    columns = np.array([desc[0] for desc in cur.description])\n",
    "    rows = np.array(cur.fetchall())\n",
    "    \n",
    "    # remove b'' characters\n",
    "    for i in np.arange(rows.shape[0]):\n",
    "        for j in np.arange(rows.shape[1]):\n",
    "            if str(rows[i][j]).startswith('b\\'') or str(rows[i][j]).startswith('b\\\"'):\n",
    "                rows[i][j] = str(rows[i][j])[2:-1]\n",
    "\n",
    "    return columns, rows\n",
    "\n",
    "def db_to_csv(db_name):\n",
    "    with create_connection(SQLITE_FILE) as conn:  # create a database connection\n",
    "        conn.text_factory = bytes\n",
    "        \n",
    "        cols, rows = select_entities(conn, db_name)\n",
    "        with open(f'ml_class_text/{str.lower(db_name)}.csv', 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(cols)\n",
    "            \n",
    "            for r in tqdm(rows):\n",
    "                writer.writerow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases: [b'Questions', b'sqlite_stat1', b'Answers', b'Tags']\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88efd106973b4195859b6a9a03bb6c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=85085.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3583adee964cff87f4e5c4b3cfaf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=84105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d640e5baf78b4dbfa41209ae7c473dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with create_connection(SQLITE_FILE) as conn:\n",
    "    conn.text_factory = bytes\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    print(f'Databases: {[db_name[0] for db_name in cursor.fetchall()]}\\n')\n",
    "\n",
    "db_to_csv('Questions')\n",
    "db_to_csv('Answers')\n",
    "db_to_csv('Tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.279567e+09</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.279567e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId  CreationDate  Score  \\\n",
       "0   6          5.0  1.279567e+09    272   \n",
       "1  21         59.0  1.279567e+09      4   \n",
       "\n",
       "                                               Title  \\\n",
       "0  The Two Cultures: statistics vs. machine learn...   \n",
       "1                     Forecasting demographic census   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>Last year, I read a blog post from <a href=...  \n",
       "1  <p>What are some of the ways to forecast demog...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_csv('ml_class_text/questions.csv', encoding='iso-8859-1')\n",
    "df_questions.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>elicitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>normality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Tag\n",
       "0   1       bayesian\n",
       "1   1          prior\n",
       "2   1    elicitation\n",
       "3   2  distributions\n",
       "4   2      normality"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags = pd.read_csv('ml_class_text/tags.csv', encoding='iso-8859-1')\n",
    "df_tags['Id'] = df_tags['Id'].apply(lambda x: x[2:-1]).astype(np.int64)\n",
    "df_tags['Tag'] = df_tags['Tag'].apply(lambda x: x[2:-1])\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  1315\n",
       "unique                 1315\n",
       "top       quasi-monte-carlo\n",
       "freq                      1\n",
       "Name: Tag, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_tags = df_tags.groupby(\"Tag\", sort='count').size().reset_index(name='count')\n",
    "grouped_tags['Tag'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>statistical-significance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>machine-learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                       Tag\n",
       "0   1                  bayesian\n",
       "3   2             distributions\n",
       "7   4             distributions\n",
       "8   4  statistical-significance\n",
       "9   6          machine-learning"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 100\n",
    "grouped_tags = df_tags.groupby('Tag').size().reset_index(name='count')\n",
    "most_common_tags = grouped_tags.nlargest(num_classes, columns='count')\n",
    "df_tags['Tag'] = df_tags['Tag'].apply(lambda tag : tag if tag in most_common_tags['Tag'].values else None)\n",
    "df_tags = df_tags.dropna()\n",
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanitization of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(body):\n",
    "    regex = re.compile('<.*?>')\n",
    "    return re.sub(regex, '', body)\n",
    "\n",
    "df_questions['Body'] = df_questions['Body'].apply(strip_html_tags)\n",
    "df_questions['Text'] = df_questions['Title'] + ' ' + df_questions['Body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denormalization of dataframe adding column with tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "question_tags = df_questions.merge(df_tags, left_on='Id', right_on='Id', how='inner').groupby('Id')['Tag'].apply(np.array)\n",
    "df_questions = df_questions.merge(pd.DataFrame({'Id': question_tags.index, 'Tags': question_tags.values}), left_on='Id', right_on='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O\\'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R\\'s fortunes\\n  package: To paraphrase provocatively,\\n  \\'machine learning is statistics minus\\n  an...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...</td>\n",
       "      <td>[forecasting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n</td>\n",
       "      <td>[bayesian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...</td>\n",
       "      <td>[hypothesis-testing, t-test, p-value, interpretation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between \\'...</td>\n",
       "      <td>[correlation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  \\\n",
       "0   6   \n",
       "1  21   \n",
       "2  22   \n",
       "3  31   \n",
       "4  36   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                              Text  \\\n",
       "0  The Two Cultures: statistics vs. machine learning? Last year, I read a blog post from Brendan O\\'Connor entitled \"Statistics vs. Machine Learning, fight!\" that discussed some of the differences between the two fields.  Andrew Gelman responded favorably to this:\\n\\nSimon Blomberg: \\n\\n\\n  From R\\'s fortunes\\n  package: To paraphrase provocatively,\\n  \\'machine learning is statistics minus\\n  an...   \n",
       "1  Forecasting demographic census What are some of the ways to forecast demographic census with some validation and calibration techniques?\\n\\nSome of the concerns:\\n\\n\\nCensus blocks vary in sizes as rural\\nareas are a lot larger than condensed\\nurban areas. Is there a need to account for the area size difference?\\nif let's say I have census data\\ndating back to 4 - 5 census periods,\\nhow far ca...   \n",
       "2                                                                                                                                                                                                                                          Bayesian and frequentist reasoning in plain English How would you describe in plain English the characteristics that distinguish Bayesian from Frequentist reasoning?\\n   \n",
       "3  What is the meaning of p values and t values in statistical tests? After taking a statistics course and then trying to help fellow students, I noticed one subject that inspires much head-desk banging is interpreting the results of statistical hypothesis tests.  It seems that students easily learn how to perform the calculations required by a given test but get hung up on interpreting the resul...   \n",
       "4  Examples for teaching: Correlation does not mean causation There is an old saying: \"Correlation does not mean causation\". When I teach, I tend to use the following standard examples to illustrate this point:\\n\\n\\nnumber of storks and birth rate in Denmark;\\nnumber of priests in America and alcoholism;\\nin the start of the 20th century it was noted that there was a strong correlation between \\'...   \n",
       "\n",
       "                                                    Tags  \n",
       "0                                     [machine-learning]  \n",
       "1                                          [forecasting]  \n",
       "2                                             [bayesian]  \n",
       "3  [hypothesis-testing, t-test, p-value, interpretation]  \n",
       "4                                          [correlation]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 400)\n",
    "df_questions[['Id', 'Text', 'Tags']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texts tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit(df_questions['Tags'])\n",
    "labels = multilabel_binarizer.classes_\n",
    "\n",
    "maxlen = 180\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words, lower=True)\n",
    "tokenizer.fit_on_texts(df_questions['Text'])\n",
    "\n",
    "def get_features(text_series):\n",
    "    \"\"\"\n",
    "    transforms text data to feature_vectors that can be used in the ml model.\n",
    "    tokenizer must be available.\n",
    "    \"\"\"\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    return pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "\n",
    "def prediction_to_label(prediction):\n",
    "    tag_prob = [(labels[i], prob) for i, prob in enumerate(prediction.tolist())]\n",
    "    return dict(sorted(tag_prob, key=lambda kv: kv[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76365, 180)\n"
     ]
    }
   ],
   "source": [
    "x = get_features(df_questions['Text'])\n",
    "y = multilabel_binarizer.transform(df_questions['Tags'])\n",
    "print(x.shape)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=9000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>count</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>r</td>\n",
       "      <td>13236</td>\n",
       "      <td>11.552811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>regression</td>\n",
       "      <td>10959</td>\n",
       "      <td>13.953189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>machine-learning</td>\n",
       "      <td>6089</td>\n",
       "      <td>25.112991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>time-series</td>\n",
       "      <td>5559</td>\n",
       "      <td>27.507285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>probability</td>\n",
       "      <td>4217</td>\n",
       "      <td>36.261086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag  count  class_weight\n",
       "986                  r  13236     11.552811\n",
       "1020        regression  10959     13.953189\n",
       "669   machine-learning   6089     25.112991\n",
       "1220       time-series   5559     27.507285\n",
       "946        probability   4217     36.261086"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_tags['class_weight'] = len(df_tags) / most_common_tags['count']\n",
    "class_weight = {}\n",
    "for index, label in enumerate(labels):\n",
    "    class_weight[index] = most_common_tags[most_common_tags['Tag'] == label]['class_weight'].values[0]\n",
    "    \n",
    "most_common_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 180, 20)           100000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 180, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 178, 300)          18300     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 148,400\n",
      "Trainable params: 148,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filter_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 20, input_length=maxlen))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jakub/Dokumenty/venv36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 54982 samples, validate on 6110 samples\n",
      "Epoch 1/20\n",
      "54982/54982 [==============================] - 26s 478us/sample - loss: 10.9755 - categorical_accuracy: 0.0711 - val_loss: 9.2225 - val_categorical_accuracy: 0.1385\n",
      "Epoch 2/20\n",
      "54982/54982 [==============================] - 24s 440us/sample - loss: 7.6982 - categorical_accuracy: 0.2443 - val_loss: 7.2428 - val_categorical_accuracy: 0.3077\n",
      "Epoch 3/20\n",
      "54982/54982 [==============================] - 24s 430us/sample - loss: 6.5354 - categorical_accuracy: 0.3236 - val_loss: 6.6091 - val_categorical_accuracy: 0.3419\n",
      "Epoch 4/20\n",
      "54982/54982 [==============================] - 24s 431us/sample - loss: 6.0471 - categorical_accuracy: 0.3523 - val_loss: 6.3136 - val_categorical_accuracy: 0.3633\n",
      "Epoch 5/20\n",
      "54982/54982 [==============================] - 23s 418us/sample - loss: 5.7496 - categorical_accuracy: 0.3669 - val_loss: 6.2020 - val_categorical_accuracy: 0.3694\n",
      "Epoch 6/20\n",
      "54982/54982 [==============================] - 23s 425us/sample - loss: 5.5409 - categorical_accuracy: 0.3767 - val_loss: 6.0363 - val_categorical_accuracy: 0.3746\n",
      "Epoch 7/20\n",
      "54982/54982 [==============================] - 22s 407us/sample - loss: 5.3814 - categorical_accuracy: 0.3819 - val_loss: 6.0002 - val_categorical_accuracy: 0.3951\n",
      "Epoch 8/20\n",
      "54982/54982 [==============================] - 22s 409us/sample - loss: 5.2535 - categorical_accuracy: 0.3856 - val_loss: 6.1131 - val_categorical_accuracy: 0.3800\n",
      "Epoch 9/20\n",
      "54982/54982 [==============================] - 23s 417us/sample - loss: 5.1378 - categorical_accuracy: 0.3909 - val_loss: 6.0611 - val_categorical_accuracy: 0.3766\n",
      "Epoch 10/20\n",
      "54982/54982 [==============================] - 24s 437us/sample - loss: 5.0350 - categorical_accuracy: 0.3948 - val_loss: 6.0680 - val_categorical_accuracy: 0.3750\n",
      "Epoch 11/20\n",
      "54982/54982 [==============================] - 24s 443us/sample - loss: 4.9441 - categorical_accuracy: 0.3980 - val_loss: 6.0879 - val_categorical_accuracy: 0.3835\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(), \n",
    "    EarlyStopping(patience=4), \n",
    "    ModelCheckpoint(filepath='ml_class_text/model_conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    class_weight=class_weight,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15273/15273 [==============================] - 1s 89us/sample - loss: 0.0551 - categorical_accuracy: 0.3773\n",
      "loss: 0.05505771553188373\n",
      "categorical_accuracy: 0.37733253836631775\n"
     ]
    }
   ],
   "source": [
    "cnn_model = tf.keras.models.load_model('ml_class_text/model_conv1d.h5')\n",
    "metrics = cnn_model.evaluate(x_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
